<!DOCTYPE html>
<html lang="en-US">

  
<!-- Mirrored from simpletext-project.com/2026/tasks by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 19 Feb 2026 13:27:18 GMT --> <!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,maximum-scale=2">
    <link rel="stylesheet" type="text/css" media="screen" href="assets/css/stylec62f.css?v=ce9a52e0f4761d87aaf9390b7e06e0137cc9710f">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Tâches | CLEF 2026 SimpleText</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Tasks" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="SimpleText est une piste organisée dans le cadre de la conférence CLEF 2026, initiée par l&apos;initiative CLEF." />
<meta property="og:description" content="SimpleText is a track organised as a part of CLEF 2026 conference, initiated by CLEF initiative." />
<link rel="canonical" href="2026/tasks.html" />
<meta property="og:url" content="2026/tasks.html" />
<meta property="og:site_name" content="CLEF 2026 SimpleText" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Tasks" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"SimpleText is a track organised as a part of CLEF 2026 conference, initiated by CLEF initiative.","headline":"Tasks","url":"http://simpletext-project.com/2026//2026/tasks.html"}</script>
<!-- End Jekyll SEO tag --> <!-- start custom head snippets, customize with your own _includes/head-custom.html file --> <!-- Setup Google Analytics --> <!-- You can set your favicon here --> <!-- link rel="shortcut icon" type="image/x-icon" href="/2026/favicon.ico" --> <!-- end custom head snippets -->

  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          
            <a id="forkme_banner" href="https://github.com/simpletext-madics/2026">Voir sur GitHub</a>
          

          <h1 id="project_title">CLEF 2026 SimpleText</h1>
          <h2 id="project_tagline">SimpleText est une piste organisée dans le cadre de <a href="https://clef2026.clef-initiative.eu/">la conférence CLEF 2026</a>, initiée par <a href="http://www.clef-initiative.eu/">l'initiative CLEF</a>.</h2>

          
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1 id="tasks">Tâches</h1>

<hr />

<table>
  <tbody>
    <tr>
      <td><a href="index.html">Accueil</a></td>
      <td><a href="CFP.html">Appel à contributions</a></td>
      <td><a href="dates.html">Dates importantes</a></td>
      <td><a href="tasks.html">Tâches</a></td>
      <td><a href="tools.html">Outils</a></td>
    </tr>
    <tr>
      <td><a href="program.html">Programme</a></td>
      <td><a href="publications.html">Publications</a></td>
      <td><a href="organizers.html">Organisateurs</a></td>
      <td><a href="contact.html">Contact</a></td>
      <td><a href="https://clef2026.clef-initiative.eu/">CLEF-2025</a></td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="how-to-participate">Comment participer</h2>
<p>Pour participer, il faut s'inscrire sur le site de la <a href="https://clef-labs-registration.dipintra.it/">CLEF</a> : <a href="https://clef-labs-registration.dipintra.it/">https://clef-labs-registration.dipintra.it/</a>.</p>

<p>Tous les membres de l'équipe doivent s'inscrire à la liste de diffusion SimpleText : <a href="https://groups.google.com/g/simpletext">https://groups.google.com/g/simpletext</a>.</p>

<p>Les données seront mises à la disposition de tous les participants inscrits.</p>

<h2 id="task-1-text-simplification-simplify-scientific-text">Tâche 1 : Simplification du texte : Simplifier le texte scientifique</h2>
<p>La CLEF 2026 SimpleText track a présenté le corpus Cochrane-auto, dérivé des résumés de la littérature biomédicale et des résumés vulgarisés des revues systématiques Cochrane. Ce corpus représente une expansion significative dans le domaine biomédical, s'appuyant sur des méthodologies utilisées pour des ensembles de données tels que Wiki-auto et Newsela-auto.</p>

<p>Cochrane-auto fournit des données parallèles authentiques produites par les mêmes auteurs, ce qui permet une véritable simplification au niveau des documents. Il intègre des techniques de simplification avancées telles que la fusion de phrases, la réorganisation et l'alignement sur la structure du discours. Cette approche contraste avec les corpus de simplification plus standard en réalignant les données au niveau du paragraphe, de la phrase et du document.</p>

<p>Nous en extrayons deux sous-tâches :</p>

<h3 id="task-11---sentence-level-scientific-text-simplification">Tâche 1.1 - Simplification de textes scientifiques au niveau de la phrase</h3>
<p>L'objectif de cette tâche est de simplifier des phrases entières extraites de l'ensemble de données Cochrane-auto</p>

<h3 id="task-12---document-level-scientific-text-simplification">Tâche 1.2 - Simplification de textes scientifiques au niveau du document</h3>
<p>L'objectif de cette tâche est de simplifier des documents entiers extraits de l'ensemble de données Cochrane-auto</p>

<h3 id="evaluation">L'évaluation</h3>
<p>Pour évaluer les résultats, nous utiliserons des mesures d'évaluation automatique standard (SARI, BLEU, LENS, BERTscore, etc.) en combinaison avec l'évaluation humaine d'échantillons de soumissions par des étudiants en traduction et des professionnels.</p>

<h2 id="task-2-controlled-creativity-identify-and-avoid-hallucination">Tâche 2 : Créativité contrôlée : Identifier et éviter les hallucinations</h2>

<p>La tâche 2 se concentre sur l'identification et l'évaluation de la génération créative et de la distorsion de l'information dans la simplification du texte.</p>

<h3 id="task-21---identify-creative-generation-at-document-level">Tâche 2.1 - Identifier la génération créative au niveau des documents</h3>

<p>Cette tâche vise à détecter la génération créative au niveau du résumé ou du document. Les participants analyseront les résultats des systèmes des années précédentes, ainsi que les résultats délibérément générés à partir de modèles connus. L'objectif est d'identifier les phrases qui sont entièrement fondées dans le texte source, à la fois sans accès aux phrases originales et avec un accès à celles-ci. En outre, les phrases qui introduisent un nouveau contenu significatif doivent être étiquetées. Cette tâche sert de défi d'identification ou d'explication a posteriori.</p>

<h3 id="task-22---detect-and-classify-information-distortion-errors-in-simplified-sentences">Tâche 2.2 - Détecter et classer les erreurs de distorsion de l'information dans des phrases simplifiées</h3>

<p>Cette tâche consiste à détecter les distorsions d'information dans les phrases simplifiées et à classer les types d'erreurs.</p>

<h3 id="task-23---avoid-creative-generation-and-perform-grounded-generation-by-design">Tâche 2.3 - Éviter la génération créative et réaliser une génération ancrée de par sa conception</h3>

<p>Cette tâche introduit un défi d'alignement de texte, mettant l'accent sur la génération de base plutôt que sur la génération créative. Cette tâche reflète la tâche 1 sur la simplification des textes et exige des soumissions par paires, avec ou sans mention explicite de la source.</p>

<h3 id="evaluation-1">L'évaluation</h3>
<ul>
  <li>La tâche 2.1 est essentiellement une tâche d'étiquetage de phrases, évaluée de manière standard (précision, rappel, F1). Pour l'évaluation au niveau des jetons, nous utilisons la méthode Jaccard standard.</li>
  <li>La tâche 2.2 est évaluée à l'aide de mesures de classification automatique standard.</li>
  <li>La tâche 2.3 sera évaluée à la fois par des mesures automatiques standard et par une évaluation humaine, comme la tâche 1 sur la simplification du texte ci-dessus. Les séries appariées nous permettent d'échantillonner les différences au niveau de la phrase et de l'expression et de les évaluer efficacement à l'aide d'outils tels que MT Unbabel.</li>
</ul>

<h2 id="task-3-leaderboardqa">Tâche 3 : LeaderBoardQA</h2>

<p>La tâche 3, connue sous le nom de LeaderBoardQA, étend une tâche pilote de CLEF 2024 axée sur l'extraction d'informations dans des documents scientifiques. Les participants sont chargés de construire un tableau de bord en utilisant des questions-réponses spécifiques à un domaine pour récupérer des mesures de performance sur les modèles d'IA. Cette tâche invite les participants à recueillir des données exactes sur les performances et des mesures pertinentes sur des modèles d'IA spécifiés, ou sur des modèles et des repères combinés, directement à partir d'un corpus scientifique. L'approche encourage l'utilisation de grands modèles linguistiques (LLM) avancés et de systèmes de génération améliorée par la recherche (RAG), avec des formats de soumission de corpus ouverts et de livres fermés.</p>

<h3 id="description">Description</h3>

<p>LeaderBoardQA nécessite l'extraction de "pépites" spécifiques d'informations liées aux performances des modèles d'IA à partir d'un corpus scientifique en texte intégral. Ces pépites comprennent des détails exacts sur les performances du modèle et des mesures pertinentes, évaluées sur la base d'une série de critères. Il est attendu des participants qu'ils tirent parti des LLM et des RAG pour une extraction précise et fiable, contribuant ainsi à la construction d'un tableau de classement complet des performances des modèles. S'appuyant sur la tâche SimpleText SOTA de CLEF 2024, cette extension élargit son champ d'application pour évaluer le potentiel de l'AQ spécifique à un domaine dans la génération d'ensembles de données de référence et l'amélioration de la transparence des performances de l'IA.</p>

<h3 id="data-and-evaluation">Données et évaluation</h3>

<p>Pour LeaderBoardQA, CLEF réutilisera les données d'entraînement alignées sur la communauté de CLEF 2024 et les améliorera avec des normes d'or annotées par l'homme pour soutenir une évaluation rigoureuse. La tâche suivra des protocoles d'évaluation de l'assurance qualité adaptés aux systèmes LLM et RAG, et les résultats seront analysés par rapport à un corpus exhaustif de référence. Cet ensemble de données constituera une ressource essentielle pour l'évaluation comparative des performances de l'assurance qualité dans les tâches d'extraction d'informations scientifiques, comme indiqué dans le document de présentation de la tâche 4 de SimpleText de la CLEF 2024.</p>

<h2 id="task-4-simpletext-2024-revisited">Tâche 4 : SimpleText 2024 revu et corrigé</h2>

<p>CLEF 2025 introduit une piste SimpleText restructurée, visant à s'adapter aux nouveaux objectifs et aux intérêts des participants. La tâche 4 sert de voie de transition, en poursuivant éventuellement le travail des tâches de CLEF 2024 en fonction de la demande. Plus précisément, il est envisagé d'exécuter à nouveau la tâche 1 relative à la sélection du contenu (recherche de résumés) et la tâche 2 relative à la détection de la complexité (identification et explication de concepts difficiles). La poursuite de ces pistes dépend de l'intérêt actif et de la contribution des participants et des organisateurs, avec des discussions prévues lors de la conférence CLEF 2024 à Grenoble.</p>

<h3 id="description-1">Description</h3>

<p>CLEF 2025 SimpleText est très différent des années précédentes. Afin de faciliter la transition vers la nouvelle configuration des pistes, nous envisageons de poursuivre l'une des autres pistes SimpleText de CLEF 2024 (Tâche 1 sur la sélection du contenu : résumé re- trieval, Tâche 2 sur la détection de la complexité : identifier et expliquer les concepts difficiles). Nous ne poursuivrons ces activités qu'à la demande et avec un intérêt suffisant de la part de nos participants actifs. Nous en discuterons avec les participants et l'équipe actuelle d'organisateurs à CLEF 2024 à Grenoble.</p>

<h3 id="data-and-evaluation-1">Données et évaluation</h3>

<p>Pour plus d'informations sur la méthodologie et les critères d'évaluation, des détails sont disponibles dans le document de synthèse de la piste LNCS par Ermakova et al. (2024b), ainsi que dans les documents de synthèse des tâches CEUR pour CLEF 2024 SimpleText Task 1 (Sanjuan et al., 2024) et Task 2 (Di Nunzio et al., 2024).</p>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        
        <p class="copyright">CLEF 2026 SimpleText maintenu par <a href="https://github.com/simpletext-madics">simpletext-madics</a></p>
        
        <p>Publié avec <a href="https://pages.github.com/">GitHub Pages</a></p>
      </footer>
    </div>
  </body>

<!-- Mirrored from simpletext-project.com/2026/tasks by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 19 Feb 2026 13:27:18 GMT -->
</html>
