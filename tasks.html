<!DOCTYPE html>
<html lang="en-US">

  
<!-- Mirrored from simpletext-project.com/2026/tasks by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 19 Feb 2026 13:27:18 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,maximum-scale=2">
    <link rel="stylesheet" type="text/css" media="screen" href="assets/css/stylec62f.css?v=ce9a52e0f4761d87aaf9390b7e06e0137cc9710f">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Tasks | CLEF 2026 SimpleText</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Tasks" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="SimpleText is a track organised as a part of CLEF 2026 conference, initiated by CLEF initiative." />
<meta property="og:description" content="SimpleText is a track organised as a part of CLEF 2026 conference, initiated by CLEF initiative." />
<link rel="canonical" href="2026/tasks.html" />
<meta property="og:url" content="2026/tasks.html" />
<meta property="og:site_name" content="CLEF 2026 SimpleText" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Tasks" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"SimpleText is a track organised as a part of CLEF 2026 conference, initiated by CLEF initiative.","headline":"Tasks","url":"http://simpletext-project.com/2026//2026/tasks.html"}</script>
<!-- End Jekyll SEO tag -->

    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/2026/favicon.ico" -->

<!-- end custom head snippets -->

  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          
            <a id="forkme_banner" href="https://github.com/simpletext-madics/2026">View on GitHub</a>
          

          <h1 id="project_title">CLEF 2026 SimpleText</h1>
          <h2 id="project_tagline">SimpleText is a track organised as a part of <a href="https://clef2026.clef-initiative.eu/">CLEF 2026 conference</a>,  initiated by <a href="http://www.clef-initiative.eu/">CLEF initiative</a>.</h2>

          
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1 id="tasks">Tasks</h1>

<hr />

<table>
  <tbody>
    <tr>
      <td><a href="index.html">Home</a></td>
      <td><a href="CFP.html">Call for papers</a></td>
      <td><a href="dates.html">Important dates</a></td>
      <td><a href="tasks.html">Tasks</a></td>
      <td><a href="tools.html">Tools</a></td>
    </tr>
    <tr>
      <td><a href="program.html">Program</a></td>
      <td><a href="publications.html">Publications</a></td>
      <td><a href="organizers.html">Organizers</a></td>
      <td><a href="contact.html">Contact</a></td>
      <td><a href="https://clef2026.clef-initiative.eu/">CLEF-2025</a></td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="how-to-participate">How to participate</h2>
<p>In order to participate, you should sign up at the <a href="https://clef-labs-registration.dipintra.it/">CLEF</a> website: <a href="https://clef-labs-registration.dipintra.it/">https://clef-labs-registration.dipintra.it/</a>.</p>

<p>All team members should join the SimpleText mailing list:
<a href="https://groups.google.com/g/simpletext">https://groups.google.com/g/simpletext</a>.</p>

<p>The data will be made available to all registered participants.</p>

<h2 id="task-1-text-simplification-simplify-scientific-text">Task 1: Text Simplification: Simplify scientific text</h2>
<p>The CLEF 2026 SimpleText track introduced the Cochrane-auto corpus, derived from biomedical literature abstracts and lay summaries from Cochrane systematic reviews. This corpus represents a significant expansion into the biomedical domain, building on methodologies used for datasets like Wiki-auto and Newsela-auto.</p>

<p>Cochrane-auto provides authentic parallel data produced by the same authors, enabling true document-level simplification. It incorporates advanced simplification techniques such as sentence merging, reordering, and alignment with discourse structure. This approach contrasts with more standard simplification corpora by realigning data at the paragraph, sentence, and document levels.</p>

<p>From that we extract two subtasks:</p>

<h3 id="task-11---sentence-level-scientific-text-simplification">Task 1.1 - Sentence-level Scientific Text Simplification</h3>
<p>The goal of this task is to simplify whole sentences extracted from the Cochrane-auto dataset</p>

<h3 id="task-12---document-level-scientific-text-simplification">Task 1.2 - Document-level Scientific Text Simplification</h3>
<p>The goal of this task is to simplify whole documents extracted from the Cochrane-auto dataset</p>

<h3 id="evaluation">Evaluation</h3>
<p>To evaluate results we will use standard automatic evaluation measures (SARI, BLEU, LENS, BERTscore, etc.) in combination with human assessment of samples of the submissions by translation students and professionals.</p>

<h2 id="task-2-controlled-creativity-identify-and-avoid-hallucination">Task 2: Controlled Creativity: Identify and Avoid Hallucination</h2>

<p>Task 2 focuses on identifying and evaluating creative generation and information distortion in text simplification.</p>

<h3 id="task-21---identify-creative-generation-at-document-level">Task 2.1 - Identify Creative Generation at Document Level</h3>

<p>This task aims to detect creative generation at the abstract or document level. Participants will analyze system outputs from previous years, along with deliberately generated outputs from known models. The goal is to identify which sentences are fully grounded in the source text, both without access to the original sentences and with access to them. Additionally, sentences that introduce significant new content must be labeled. This task serves as a post-hoc identification or explanation challenge.</p>

<h3 id="task-22---detect-and-classify-information-distortion-errors-in-simplified-sentences">Task 2.2 - Detect and Classify Information Distortion Errors in Simplified Sentences</h3>

<p>This task focuses on detecting information distortion in simplified sentences and classifying the types of errors.</p>

<h3 id="task-23---avoid-creative-generation-and-perform-grounded-generation-by-design">Task 2.3 - Avoid Creative Generation and Perform Grounded Generation by Design</h3>

<p>This task introduces a text alignment challenge, emphasizing grounded generation over creative generation. This task mirrors Task 1 on text simplification and requires submissions in paired runs, both with and without explicit source attribution.</p>

<h3 id="evaluation-1">Evaluation</h3>
<ul>
  <li>Task 2.1 is essentially a sentence label task, evaluated in the standard way (Precision, Recall, F1). For token-level evaluation, we use standard Jaccard.</li>
  <li>Task 2.2 is evaluated using standard automatic classification measures.</li>
  <li>Task 2.3 will be evaluated by both standard automatic measures and human evaluation, similar to Task 1 on Text Simplification above. The paired runs enable us to sample  differences at the sentence and phrase levels and evaluate them efficiently, using tools like MT Unbabel.</li>
</ul>

<h2 id="task-3-leaderboardqa">Task 3: LeaderBoardQA</h2>

<p>Task 3, known as LeaderBoardQA, extends a pilot task from CLEF 2024 focused on information extraction in scientific documents. Participants are tasked with constructing a leaderboard-like output by using domain-specific question-answering (QA) to retrieve performance metrics on AI models. This task challenges participants to gather exact performance data and relevant metrics on specified AI models, or on models and benchmarks combined, directly from a scientific corpus. The approach encourages using advanced Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems, with both open-corpus and closed-book submission formats supported.</p>

<h3 id="description">Description</h3>

<p>LeaderBoardQA requires extracting specific ânuggetsâ of information related to AI model performance from a full-text scientific corpus. These nuggets include exact details on model performance and relevant metrics, assessed across a range of benchmarks. Participants are expected to leverage LLMs and RAGs for accurate and reliable extraction, aiding in the construction of a comprehensive leaderboard for model performance. Building upon CLEF 2024’s SimpleText SOTA task, this extension broadens its scope to evaluate the potential of domain-specific QA in generating benchmark datasets and improving AI performance transparency.</p>

<h3 id="data-and-evaluation">Data and evaluation</h3>

<p>For LeaderBoardQA, CLEF will reuse community-aligned training data from CLEF 2024 and enhance it with human-annotated gold standards to support rigorous evaluation. The task will follow QA evaluation protocols tailored for LLM and RAG systems, with results analysed against a comprehensive gold-standard corpus. This dataset will serve as a critical resource for benchmarking QA performance on scientific information extraction tasks, as detailed in the CLEF 2024 SimpleText Task 4 overview paper.</p>

<h2 id="task-4-simpletext-2024-revisited">Task 4: SimpleText 2024 Revisited</h2>

<p>CLEF 2025 introduces a restructured SimpleText track, aimed at adapting to new objectives and participant interests. Task 4 serves as a transitional track, potentially continuing work from CLEF 2024 tasks based on demand. Specifically, it considers re-running Task 1 on Content Selection (abstract retrieval) and Task 2 on Complexity Spotting (identifying and explaining difficult concepts). The continuation of these tracks is contingent on active interest and input from participants and organisers, with discussions planned at the CLEF 2024 conference in Grenoble.</p>

<h3 id="description-1">Description</h3>

<p>CLEF 2025 SimpleText is very different from the earlier years. In order to facilitate the transition to the new track setup, we consider continuing one of the other CLEF 2024 SimpleText tracks (Task 1 on Content Selection: abstract re- trieval, Task 2 on Complexity Spotting: identifying and explaining difficult concepts). We will only continue those activities at the request of, and with sufficient interest from, our active participants. We will discuss this with participants and the current team of organisers at CLEF 2024 in Grenoble</p>

<h3 id="data-and-evaluation-1">Data and evaluation</h3>

<p>For further reference on methodology and evaluation criteria, details are available in the LNCS track overview paper by Ermakova et al. (2024b), as well as in the CEUR task overview papers for CLEF 2024 SimpleText Task 1 (Sanjuan et al., 2024) and Task 2 (Di Nunzio et al., 2024).</p>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        
        <p class="copyright">CLEF 2026 SimpleText maintained by <a href="https://github.com/simpletext-madics">simpletext-madics</a></p>
        
        <p>Published with <a href="https://pages.github.com/">GitHub Pages</a></p>
      </footer>
    </div>
  </body>

<!-- Mirrored from simpletext-project.com/2026/tasks by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 19 Feb 2026 13:27:18 GMT -->
</html>
